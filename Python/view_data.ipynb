{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage as spndim\n",
    "import pandas as pd\n",
    "import matplotlib.colors as clr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as mcm\n",
    "import matplotlib.colorbar as mcb\n",
    "import matplotlib.ticker as mtk\n",
    "import utils.engine as ue\n",
    "import utils.visualizer as uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext line_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"animation.html\"] = \"jshtml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9b44f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/01-forcing.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# cols_1 = [colname.replace('\\n', '') for colname in arr[0].split(\" \") if colname]\n",
    "# file_1 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c57cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/02-hs-hi_thickness.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# cols_2 = [colname.replace('\\n', '') for colname in arr[0].split(\" \") if colname]\n",
    "# file_2 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af79d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/06-depth_pit.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# file_6 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr])\n",
    "# file_6[:, 0] = np.round(file_6[:, 0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e1a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/07-pit_fcond.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# cols_7 = [colname.replace('\\n', '') for colname in arr[0].split(\" \") if colname]\n",
    "# file_7 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba73ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/08-tocn.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# file_8 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f01daab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/09-focn.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# cols_9 = [colname.replace('\\n', '') for colname in arr[0].split(\" \") if colname]\n",
    "# file_9 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad65c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/10-temp.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# file_10 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5a4000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"Validation/SHEBA_Data/11-turbflux.dat\") as file:\n",
    "#     arr = file.readlines()\n",
    "    \n",
    "# cols_11 = [colname.replace('\\n', '') for colname in arr[0].split(\" \") if colname]\n",
    "# file_11 = np.array([[float(el) for el in line.split(\" \") if el] for line in arr[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8096991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(file_1, columns=cols_1)\n",
    "\n",
    "# data_2 = pd.DataFrame(file_2, columns=cols_2)\n",
    "# data = data.merge(data_2.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_2['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_6 = pd.DataFrame(file_6, columns=['jday', 'hs', 'hi', 'hs_level', 'hf_level', 'hi_level'])\n",
    "# data = data.merge(data_6.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_6['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_7 = pd.DataFrame(file_7, columns=cols_7)\n",
    "# data = data.merge(data_7.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_7['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_8 = pd.DataFrame(file_8, columns=['jday', 'Tocn'])\n",
    "# data = data.merge(data_8.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_8['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_9 = pd.DataFrame(file_9, columns=cols_9)\n",
    "# data = data.merge(data_9.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_9['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_10 = pd.DataFrame(file_10, columns=['jday'] + ['T_{}'.format(i) for i in range(1, 51)])\n",
    "# data = data.merge(data_10.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_10['jday']*1000).astype('int32')).iloc[:, 1:]\n",
    "\n",
    "# data_11 = pd.DataFrame(file_11, columns=cols_11)\n",
    "# data = data.merge(data_11.iloc[:, 1:],\n",
    "#                   left_on=(data['jday']*1000).astype('int32'),\n",
    "#                   right_on=(data_11['jday']*1000).astype('int32')).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9f8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('Validation/full_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Validation/SHEBA_Data/12-levels.dat\") as file:\n",
    "    Z = [float(z.replace(' ', '')[:-1]) for z in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe61fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Validation/full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db652813",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = 5.\n",
    "cmap_base = plt.get_cmap('rainbow')\n",
    "vmin = data.loc[:, 'T_1':'T_50'].values.min()\n",
    "vmax = data.loc[:, 'T_1':'T_50'].values.max()\n",
    "\n",
    "boundaries = np.concatenate(([vmin], np.arange(np.floor(vmin + prec), vmax, prec), [vmax]))\n",
    "centers = (boundaries[1:] + boundaries[:-1])/2\n",
    "centers_scaled = (centers - vmin) / (vmax - vmin)\n",
    "\n",
    "cmap_custom = clr.ListedColormap([cmap_base(x) for x in centers_scaled])\n",
    "norm_custom = clr.BoundaryNorm(boundaries, cmap_custom.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65085a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(data.loc[:, 'T_1':'T_50'].T,\n",
    "           aspect='auto', cmap=cmap_custom, norm=norm_custom,\n",
    "           extent=[data.loc[0, 'jday'], data.loc[data.index[-1], 'jday'], Z[-1], Z[0]])\n",
    "plt.plot(data['jday'], data['hs_level'], color='white', lw=3, ls=':', label='snow surface')\n",
    "plt.plot(data['jday'], data['hf_level'], color='white', lw=3, ls='--', label='snow-ice interface')\n",
    "plt.plot(data['jday'], data['hi_level'], color='white', lw=3, label='ice base')\n",
    "plt.plot(data['jday'], data['hs_best'], color='black', lw=3, ls=':', label='snow surface best')\n",
    "plt.xticks(size=15)\n",
    "plt.yticks(size=15)\n",
    "plt.legend(loc='lower left', facecolor='black', labelcolor='white', prop={'size': 20})\n",
    "plt.colorbar(ticks=boundaries)\n",
    "# plt.savefig('test-image.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b69823a",
   "metadata": {},
   "source": [
    "Судя по статье (Fig.5 (a), (b)), чёрные точки - это метод приближения, использованный в статье Хувальда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a26622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma mesh\n",
    "dsigma_ice = np.full(20, 1.0/20)\n",
    "dsigma_snow = np.full(5, 1.0/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f11940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init state from data\n",
    "T_ice_init, T_snow_init, Toi_init, Tis_init, Tsa_init, \\\n",
    "dzi_init, dzs_init = ue.get_init_from_data(data, Z, dsigma_ice, dsigma_snow)\n",
    "\n",
    "time_arr = ((data['jday'] - data.loc[0, 'jday'])*24*3600).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process from data\n",
    "process_data = ue.process_from_data(Z,\n",
    "                                 data.loc[:, 'T_1':'T_50'].values, \n",
    "                                 data['Tib_interp'].values, data['Tis_interp'].values,\n",
    "                                 data['Tss'].values,\n",
    "                                 data['hi_best'].values, data['hf_best'].values,\n",
    "                                 data['hs_best'].values,\n",
    "                                 np.ones(20)/20.0, np.ones(5)/5.0,\n",
    "                                 time_arr, ue.rho_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75360c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcing\n",
    "e_s = lambda T: 6.11*np.exp(ue.c1_i*T/(T + ue.T0 - ue.c2_i))\n",
    "q_surf = lambda T: 0.622*e_s(T)/(ue.P_surf - 0.378*e_s(T))\n",
    "\n",
    "albe = data['albe'].values\n",
    "Tib_interp = data['Tib_interp'].values\n",
    "tair = data['tair'].values\n",
    "uair = data['uair'].values\n",
    "qair = data['qair'].values\n",
    "prec = data['prec_eff'].values\n",
    "swdo = data['swdo'].values\n",
    "lwdo = data['lwdo'].values\n",
    "focn_pit = data['focn_pit'].values\n",
    "Focn_y = data['Focn_y'].values\n",
    "\n",
    "\n",
    "find_index_fast = lambda time_sec: np.searchsorted(time_arr, time_sec, side='right') - 1\n",
    "albedo = lambda time: albe[find_index_fast(time)]\n",
    "Toi = lambda time: Tib_interp[find_index_fast(time)]\n",
    "T_a = lambda time: tair[find_index_fast(time)] - ue.T0\n",
    "u_a = lambda time: uair[find_index_fast(time)]\n",
    "q_a = lambda time: qair[find_index_fast(time)] * 1e-3\n",
    "p = lambda time: prec[find_index_fast(time)] * ue.mmd_to_ms\n",
    "F_sw = lambda time: swdo[find_index_fast(time)]\n",
    "F_lw = lambda time: lwdo[find_index_fast(time)]\n",
    "F_bolz = lambda T: -ue.sigma*(T + ue.T0)**4\n",
    "F_sh = lambda T, time: ue.rho_a*ue.c_pa*ue.C_sh*u_a(time)*(T_a(time) - T)\n",
    "F_lh = lambda T, time: ue.rho_a*ue.L_s0*ue.C_lh*u_a(time)*(q_a(time) - q_surf(T))\n",
    "F_P = lambda T, time: p(time)*ue.rho_w*ue.c_pw*max(T_a(time) - T, 0)\n",
    "F_atm = lambda T, time, i_0: ue.emissivity*(F_lw(time) + F_bolz(T)) \\\n",
    "                           + (1 - albedo(time))*(1 - i_0)*F_sw(time) \\\n",
    "                           + F_sh(T, time) + F_P(T, time) + F_lh(T, time) \n",
    "\n",
    "F_atm_ice = lambda T, time: F_atm(T, time, ue.i0_i)\n",
    "F_atm_snow = lambda T, time: F_atm(T, time, ue.i0_s)\n",
    "F_ocn = lambda T, time: Focn_y[find_index_fast(time)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90853d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "process_sim = ue.main_process \\\n",
    "(\n",
    "    time_step=3600.0,\n",
    "    time_end=7774*3600.0,\n",
    "    N_pseudoiter=50,\n",
    "    Ti_init=T_ice_init,\n",
    "    Ts_init=T_snow_init,\n",
    "    Tis_init=Tis_init,\n",
    "    Tsa_init=Tsa_init,\n",
    "    dzi_init=dzi_init,\n",
    "    dzs_init=dzs_init,\n",
    "    salinity=np.linspace(4.0, 1.0, len(dzi_init)),\n",
    "    snow_thickness_threshold=0.01,\n",
    "    Toi=Toi,\n",
    "    Ta=T_a,\n",
    "    p=p,\n",
    "    F_atm_ice=F_atm_ice,\n",
    "    F_atm_snow=F_atm_snow,\n",
    "    F_sw=F_sw,\n",
    "    F_ocn=F_ocn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ff5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_anim = uv.animate([process_data], ue.rho_w, ue.rho_s, clip_end=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d262d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_anim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b92cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = uv.timeseries_img(process_data, y_points=100)#, savepath='timeseries.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv.timeseries_img(process_data, y_points=200,\n",
    "                  cmap_ice='RdBu', tmin_ice=-25, tmax_ice=2, step_ice=1.0,\n",
    "                  cmap_snow='RdBu', tmin_snow=-25, tmax_snow=2, step_snow=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b641f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rho_water=ue.rho_w\n",
    "# rho_snow=ue.rho_s\n",
    "# y_points=100\n",
    "# t_min=None\n",
    "# t_max=None\n",
    "# rgb_background = [208, 245, 226]\n",
    "# levels_fill = np.arange(-6, 6.1, 0.5)\n",
    "# levels_border = [-3, -2, -1, -0.5, 0.5, 1, 2]\n",
    "# border_intense = 4\n",
    "# sigma_x = 0.0\n",
    "# sigma_y = 15.0\n",
    "# figsize=(30, 10)\n",
    "# cmap='seismic'\n",
    "\n",
    "# Z_i_data, Z_s_data = uv.get_Z(process_data, rho_snow, rho_water)\n",
    "# Z_i_sim, Z_s_sim = uv.get_Z(process_sim, rho_snow, rho_water)\n",
    "# z_min = min(np.concatenate((Z_i_sim[:, 0], Z_i_data[:, 0])))\n",
    "# z_max = max(np.concatenate((Z_s_sim[:, -1], Z_s_data[:, -1])))\n",
    "\n",
    "# Z_mesh = np.linspace(z_min, z_max, y_points + 1)\n",
    "# temp_mesh_data = np.array([np.interp(x=Z_mesh,\n",
    "#                                      xp=np.concatenate((Z_i_line, (Z_s_line[1:] if has_snow else []))),\n",
    "#                                      fp=np.concatenate(([T_oi], T_i_line, [T_is],\n",
    "#                                                        (T_s_line if has_snow else []),\n",
    "#                                                        ([T_sa] if has_snow else [])\n",
    "#                                                        )),\n",
    "#                                      left=np.nan, right=np.nan\n",
    "#                                      ) \\\n",
    "#                       for Z_i_line, Z_s_line, T_oi, T_i_line, T_is, T_s_line, T_sa, has_snow \\\n",
    "#                       in zip(Z_i_data, Z_s_data,\n",
    "#                              process_data.oi_temp_history, process_data.ice_temp_history,\n",
    "#                              process_data.is_temp_history, process_data.snow_temp_history,\n",
    "#                              process_data.sa_temp_history, process_data.snow_presence_history\n",
    "#                             )\n",
    "#                            ])\n",
    "# temp_mesh_sim = np.array([np.interp(x=Z_mesh,\n",
    "#                                     xp=np.concatenate((Z_i_line, (Z_s_line[1:] if has_snow else []))),\n",
    "#                                     fp=np.concatenate(([T_oi], T_i_line, [T_is],\n",
    "#                                                        (T_s_line if has_snow else []),\n",
    "#                                                        ([T_sa] if has_snow else [])\n",
    "#                                                        )),\n",
    "#                                     left=np.nan, right=np.nan\n",
    "#                                     ) \\\n",
    "#                       for Z_i_line, Z_s_line, T_oi, T_i_line, T_is, T_s_line, T_sa, has_snow \\\n",
    "#                       in zip(Z_i_sim, Z_s_sim,\n",
    "#                              process_sim.oi_temp_history, process_sim.ice_temp_history,\n",
    "#                              process_sim.is_temp_history, process_sim.snow_temp_history,\n",
    "#                              process_sim.sa_temp_history, process_sim.snow_presence_history\n",
    "#                             )\n",
    "#                           ])\n",
    "\n",
    "# data = (temp_mesh_sim - temp_mesh_data).T\n",
    "\n",
    "# fig = plt.figure(figsize=figsize)\n",
    "# ax = plt.axes()\n",
    "# ax.set_facecolor(np.array(rgb_background)/256.0)\n",
    "# contourf = ax.contourf(gauss_filter_with_nans(data, (sigma_x, sigma_y)),\n",
    "#                        levels=levels_fill, cmap=cmap, extend='both',\n",
    "#                        extent=[process_data.timeline[0]/3600, process_data.timeline[-1]/3600,\n",
    "#                                Z_mesh[0], Z_mesh[-1]]\n",
    "#                       )\n",
    "# contour = ax.contour(gauss_filter_with_nans(data, (sigma_x, sigma_y)),\n",
    "#                      levels=levels_border, cmap=cmap,\n",
    "#                      norm=clr.Normalize(vmin=-2, vmax=2, clip=True),\n",
    "#                      linewidths=2.5, linestyles='--',\n",
    "#                      extent=[process_data.timeline[0]/3600, process_data.timeline[-1]/3600,\n",
    "#                              Z_mesh[0], Z_mesh[-1]])\n",
    "# ax.clabel(contour, fontsize=20)\n",
    "\n",
    "# # ax.axhline(lw=3, ls='--', color='c')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_i_data[:, 0], lw=1.5, color='black')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_i_data[:, -1], lw=1.5, color='black')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_s_data[:, -1], lw=1.5, color='black', label='data')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_i_sim[:, 0], lw=3, ls=':', color='black')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_i_sim[:, -1], lw=3, ls=':', color='black')\n",
    "# ax.plot(process_data.timeline/3600.0, Z_s_sim[:, -1], lw=3, ls=':', color='black', label='simulation')\n",
    "\n",
    "# ax.set_xlabel('t, hours', size=20)\n",
    "# ax.set_ylabel('Z, m', size=20)\n",
    "# ax.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "\n",
    "# cax = fig.add_axes([ax.get_position().x0, ax.get_position().y0 - 0.15,\n",
    "#                     ax.get_position().width, 0.05])\n",
    "# colorbar = fig.colorbar(contourf, cax=cax, orientation='horizontal', ticks=contourf.levels, drawedges=True)\n",
    "# colorbar.outline.set_linewidth(3)\n",
    "# colorbar.dividers.set_linewidth(3)\n",
    "# colorbar.dividers.set_dashes((-0.5, (2.5, 6.5)))\n",
    "# cax_ice.tick_params(axis='x', labelsize=15)\n",
    "# ax.legend(prop={'size':20})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5692ae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv.timeseries_err(process_sim, process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv.timeseries_err(process_sim, process_data, tmin_err=-4., tmax_err=4., step_err=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "uv.timeseries_err(process_sim[5000:6500], process_data[5000:6500], tmin_err=-4., tmax_err=4., step_err=.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
